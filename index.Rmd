---
title: "Predictive Analysis of Machine Learning"
author: "Sam"
date: "April 14, 2016"
output: html_document
---

#Loading data:

#R sessions:
```{r}
train_data <- read.csv('pml-training.csv', stringsAsFactors=F, sep=',', header=T, quote="",na.strings=c("#DIV/0!"," ", "", "NA")); 
test_data <- read.csv('pml-testing.csv', stringsAsFactors=F, sep=',', header=T, quote="",na.strings=c("#DIV/0!"," ", "", "NA"));
```

#Cleaning data
#1) cleaning training data
```{r}
Missing_values <- sapply(train_data, function (x) any(is.na(x) | x == ""));
#defining the missing values in training data

Predictors <- !Missing_values & grepl("belt|[^(fore)]arm|dumbbell|forearm", names(Missing_values));
# removing the variables with missing values and using data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants based on the instructions.

Candidates <- names(Missing_values)[Predictors];
#Selecting the candidate variables

train_data_candidate <- train_data[, c("X.classe.", Candidates)]; 
#adding X.classes. as instructed 
dim(train_data_candidate); 
# 86 variables exist to incorporate 19622 rows

names(train_data_candidate) <- gsub("X.","",names(train_data_candidate)); 
names(train_data_candidate) <- gsub(".$","",names(train_data_candidate)); 
#converting the names of variables as instructed

train_data_candidate$classe <- as.factor(train_data_candidate$classe); 
#setting variable classe as a categorical factor

table(train_data_candidate$classe)
```

```{r}
suppressMessages(library(caret)); 
suppressMessages(library(data.table));  

nzv <- nearZeroVar(train_data_candidate,saveMetrics=TRUE); 
train_data_candidate<-train_data_candidate[,-which(nzv$nzv==T)]; 
#removing variables with near zero variances 
dim(train_data_candidate); 
#now, there are 53 variables remaining

#preprocessing the candidate variables by methods of centering and scaling, and skipping the first variable of classe
prepro <- preProcess(train_data_candidate[,-1],method=c("center","scale")); 
train_data_candidate[,-1]<-predict(prepro, train_data_candidate[,-1]); 
#preprocessing values in the train_data_candidate data set
```

```{r}
#verifying the variable correlation in prior to applying models
suppressMessages(library(corrplot)); 
corrplot(cor(train_data_candidate[,-1][,-length(names(test_data))]),method="color",main="variable correlation in train data"); 
```

#2) cleaning testing data through the same processes
```{r}
Missing_values <- sapply(test_data, function (x) any(is.na(x) | x == "")); 
Predictor <- !Missing_values & grepl("belt|[^(fore)]arm|dumbbell|forearm", names(Missing_values)); 
Candidates <- names(Missing_values)[Predictor]; 

test_data_candidate <- test_data[,  Candidates]; 
dim(test_data_candidate); 
# there are 85 variables with 20 samples

names(test_data_candidate) <- gsub("X.","",names(test_data_candidate)); 
names(test_data_candidate) <- gsub(".$","",names(test_data_candidate)); 

nzv <- nearZeroVar(test_data_candidate,saveMetrics=TRUE); 
test_data_candidate<-test_data_candidate[,-which(nzv$nzv==T)]; 
dim(test_data_candidate); 
#there are 52 variable to incorporate 20 samples

prepro <- preProcess(test_data_candidate,method=c("center","scale")); 
test_data_candidate<-predict(prepro, test_data_candidate); 
#preprocessing values in the test_data_candidate data set
```

#######
#Training the selected models (random forest and tree)

#Splitting data: (60% for training and 40% for testing as probes)
```{r}
set.seed(100); 
idx <- createDataPartition(train_data_candidate$classe, p=0.6, list=FALSE); 
train <- train_data_candidate[idx,]; 
test_probe <- train_data_candidate[-idx,]; 

dim(train); 
#there are 11776 values in each row with 53 variables
dim(test_probe); 
#there are 7846 samples with 53 variables
```

#Model random forest was selected for this project due to several advantages as follows:
#1)  most accurate,generally; 
#2)  efficient on big data; 
#3)  suitable for analyzing on many variables; 
#4)  good at estimating variable importance;

#Training random forest model with 5 fold cross validation 
```{r}
fitrf <- train(classe ~ ., data=train, method="rf", trControl=trainControl(method="cv", 5), ntree=250); 
print(fitrf); 
#The estimated accuracy is 98.86%
```

```{r}
plot(fitrf$finalModel,col=c(1:6),lwd=3,main="Accuracies vs No. of trees"); 
legend("topright",inset=.05,title="classe",legend=colnames(fitrf$finalModel$err.rate),fill=c(1:6),horiz=F,cex=.8); 
```

#identifying the important variables
```{r}
varImp(fitrf); 
# showing only top 20 most important variables (out of 52)
```

#Evaluating the test_probe data 
```{r}
predrf <- predict(fitrf,test_probe); 
confusionMatrix(test_probe$classe, predrf); 
cmrf <- confusionMatrix(test_probe$classe, predrf); 

accuracy <- postResample(predrf, test_probe$classe); 
print(accuracy); 
#The estimated accuracy is 99.2% in test_probe data set
```

```{r}
qplot(classe,predrf,data=test_probe,col=classe, main="relationship of model predicted and classe in train_probe"); 
#the relationship of model predicted and classes in test_probe dataset
```

#Prediction of the cleaned test_data data set by applying the trained fitrf model generated above
```{r}
testPred <- predict(fitrf, newdata=test_data_candidate); 

```

# Comparing with Tree model
```{r}
fittree<- train(classe ~ ., method="rpart", data=train); 
#training the tree model
predtree <- predict(fittree,test_probe); 
#evaluating the trained tree model by test_probe data set
confusionMatrix(test_probe$classe,predtree); 
cmtree <- confusionMatrix(test_probe$classe,predtree); 
# the estimated accuracy of trained trine model is 49.46% which is a lot worse than the trained random forest model
```

```{r}
suppressMessages(library(rattle)); 
fancyRpartPlot(fittree$finalModel); 
#plotting predictive result by tree  
```

#Comparing the predicted model between tree (predtree) and random forest (predrf)
```{r}
table(predrf, predtree); 
```

#Sensitivities & Specificities of predicted models (random forest vs tree) 
```{r} 
par(mfrow=c(1,2)); 
plot(cmrf$byClass, main="random forest", xlim=c(0.97, 1.005),pch=19,col="red"); 
text(cmrf$byClass[,1]+0.005, cmrf$byClass[,2], labels=LETTERS[1:5], cex= 0.7); 

plot(cmtree$byClass, main="tree", xlim=c(0.3, 1.005), ylim=c(0.01,1),pch=19,col="blue"); 
text(cmtree$byClass[,1]+0.05, cmtree$byClass[,2], labels=LETTERS[1:5], cex= 0.7)
```

# There are many inconsistent predictions between these two models in the classes of A to E as shown above.
# The prediction by random forest model is a lot better than that by tree model based on the accuracies estimated (98.86% vs 49.46%) on tested probe dataset.
